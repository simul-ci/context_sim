# Two evaluation prompts for synthetic user quality:
# 1. BELIEVABILITY_CHECK_PROMPT — test whether the agent can distinguish
#    items it interacted with from unseen ones (memory consistency check).
# 2. LLM_EVALUATOR_PROMPT — an external LLM judges whether interaction
#    traces look human-generated or AI-generated.

BELIEVABILITY_CHECK_PROMPT = """### Instructions

1. Review each {item_type} in the ## Recommended List ##.
2. For each {item_type}, classify if you have already interacted with it ("Interacted") or if you have not ("Not Interacted").
"""

LLM_EVALUATOR_PROMPT = """Please evaluate the following interactions of an agent with a recommender system, and determine whether it is generated by a Large Language Model (LLM) AI or a real human:
{interaction_logs}

Please rate on a scale of 1 to 5, with 1 being most like an AI and 5 being most like a human.
"""
